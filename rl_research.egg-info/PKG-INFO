Metadata-Version: 2.2
Name: rl_research
Version: 0.1.0
Summary: Reinforcement Learning Research Framework
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: gymnasium[all]>=0.29.1
Requires-Dist: stable-baselines3[extra]>=2.2.1
Requires-Dist: torch>=2.1.0
Requires-Dist: wandb>=0.16.0
Requires-Dist: hydra-core>=1.3.2
Requires-Dist: omegaconf>=2.3.0
Requires-Dist: matplotlib>=3.8.0
Requires-Dist: seaborn>=0.13.0
Requires-Dist: PyYAML>=6.0.1
Requires-Dist: pytest>=7.0.0
Requires-Dist: tensorboard>=2.15.0
Requires-Dist: opencv-python>=4.8.0
Requires-Dist: ale-py>=0.8.0
Requires-Dist: autorom[accept-rom-license]>=0.6.1
Requires-Dist: box2d-py>=2.3.5

# RL Research Framework

A modular framework for reinforcement learning research with integrated experiment tracking and configuration management.

## Project Structure
```
rl_research/
├── algorithms/
│   └── custom/
├── environments/
│   ├── wrappers/
│   └── custom_envs/
├── experiments/
│   ├── configs/
│   │   ├── algorithm/
│   │   ├── env/
│   │   └── experiment.yaml
│   ├── runs/
│   └── cli.py
├── utils/
└── tests/
```

## Setup

1. Create and activate conda environment:
```bash
conda create -n rl-research python=3.10
conda activate rl-research
```

2. Install the package in development mode:
```bash
pip install -e .
```

3. Set up Weights & Biases:
```bash
# Set your WANDB API key
export WANDB_API_KEY=your_key_here
```

## Running Experiments

Basic experiment:
```bash
python -m experiments.cli
```

Parameter sweep:
```bash
python -m experiments.cli algorithm.params.learning_rate=0.0001,0.0003,0.001
```

Multiple seeds:
```bash
python -m experiments.cli experiment.seed=1,2,3,4,5
``` 
