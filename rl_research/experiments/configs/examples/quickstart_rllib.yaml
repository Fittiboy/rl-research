# ==============================================
# Quick Start Configuration with RLlib
# ==============================================

# Environment settings
env:
  name: "cartpole"
  type: "gym"
  id: "CartPole-v1"
  params:
    max_episode_steps: 500

# Algorithm settings
algorithm:
  name: "ppo"
  type: "rllib"
  params:
    # Training settings
    num_workers: 2  # Number of parallel workers
    num_gpus: 1  # Number of GPUs to use
    framework: "torch"  # Can be "torch" or "tf2"
    
    # PPO specific settings
    train_batch_size: 4000
    sgd_minibatch_size: 128
    num_sgd_iter: 30
    lr: 3e-4
    gamma: 0.99
    lambda_: 0.95
    clip_param: 0.2
    vf_clip_param: 10.0
    entropy_coeff: 0.0
    vf_loss_coeff: 1.0
    
    # Model architecture
    model:
      fcnet_hiddens: [64, 64]
      fcnet_activation: "tanh"
    
    # Exploration settings
    explore: true
    exploration_config:
      type: "StochasticSampling"

# Experiment settings
experiment:
  name: "${algorithm.name}_rllib_${env.name}"
  seed: 42
  total_timesteps: 50000
  eval_frequency: 5000  # Evaluate every 5000 steps

# Video recording settings
video:
  enabled: true
  record_freq: 1  # Record every evaluation
  num_episodes: 2
  fps: 30
  local:
    enabled: false
    dir: "${hydra:runtime.output_dir}/videos"
    format: "mp4"
  wandb:
    enabled: true
    prefix: "${experiment.name}"

# WandB settings
wandb:
  project: "rl_research"
  group: "${experiment.name}"
  tags: ["quickstart", "rllib", "video_recording"]
  mode: ${oc.env:WANDB_MODE,"online"}
  dir: ${hydra:runtime.output_dir} 